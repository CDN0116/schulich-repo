{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imoort data\n",
    "df=pd.read_csv('https://raw.githubusercontent.com/delinai/schulich_ds1/main/Datasets/bikes_sharing.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data frame check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2.data frame checks:\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()#missing data/incorrect data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # range make sense? any outliers? define the categorical/numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ca'].unique() # to see the unique value of the column if it's strange"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.data cleaning \n",
    "missing_percentage = (df.isnull().sum() / len(df)) * 100\n",
    "# or\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# clean missing data #fill missing data with the mean of age/ embarked represents the port \n",
    "df['Age'] = df['Age'].fillna(df.groupby('Sex')['Age'].transform('mean'))\n",
    "df['Embarked'] = df['Embarked'].fillna('S')\n",
    "\n",
    "# drop those useless columns \n",
    "df.drop(['alive','alone','embark_town','who','adult_male','deck','class'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. data exploration\n",
    "# #Display the distribution of target value-'Survived'\n",
    "sns.countplot(x='Survived', data=df)\n",
    "plt.show()\n",
    "\n",
    "# #More detailed exploration\n",
    "sns.pairplot(df, hue='Survived')\n",
    "plt.show()\n",
    "\n",
    "#using boxplot to check each continuous variables:\n",
    "sns.boxplot(x='target value', y='age', data=df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ((ax1,ax2,ax3),(ax4,ax5,ax6)) = plt.subplots(2,3, figsize=(20,10))\n",
    "sns.boxplot(x='DEATH_EVENT', y='age', ax=ax1, data=df)\n",
    "sns.boxplot(x='DEATH_EVENT', y='ejection_fraction', ax=ax2, data=df)\n",
    "sns.boxplot(x='DEATH_EVENT', y='serum_sodium', ax=ax3, data=df)\n",
    "sns.boxplot(x='DEATH_EVENT', y='creatinine_phosphokinase', ax=ax4, data=df)\n",
    "sns.boxplot(x='DEATH_EVENT', y='platelets', ax=ax5, data=df)\n",
    "sns.boxplot(x='DEATH_EVENT', y='serum_creatinine', ax=ax6, data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the outliers\n",
    "bedrooms_outliers=df[df['bedrooms']>30].index\n",
    "df.drop(bedrooms_outliers,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using groupby checking the categorical columns\n",
    "df_anaemia = df.groupby(['DEATH_EVENT','anaemia'])[['sex']].count().unstack()\n",
    "df_anaemia['total'] = df_anaemia['sex'][0] + df_anaemia['sex'][1]\n",
    "df_anaemia['percent_0'] = df_anaemia['sex'][0] / df_anaemia['total']\n",
    "df_anaemia['percent_1'] = df_anaemia['sex'][1] / df_anaemia['total']\n",
    "df_anaemia\n",
    "\n",
    "#using the plot bar chart:\n",
    "df.groupby(['hd_cons','thal'])['ca'].count().unstack().plot(kind='bar', stacked=True)\n",
    "# or\n",
    "df.groupby('embarked').count() #看‘embarked’一栏的值在其他栏的分布情况，可以看出embarked栏内哪个值最多，就可以用这个值来fillin missing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. feature engineering\n",
    "#generate new features :\n",
    "#translate continuous bariable into groups\n",
    "sns.histplot(df.casual)\n",
    "\n",
    "df.casual.describe()\n",
    "\n",
    "def casual_category(x):\n",
    "    if x >= 0 and x <= 4:\n",
    "        return 0\n",
    "    elif x > 4 and x <= 17:\n",
    "        return 1\n",
    "    elif x >17 and x <= 49:\n",
    "        return 2\n",
    "    elif x > 49:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['casual_cat'] = df['casual'].apply(casual_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dummies：\n",
    "sex_dummies = pd.get_dummies(df['sex'])\n",
    "embarked_dummies = pd.get_dummies(df['embarked'])\n",
    "#这里sex、embarked栏原本type为object\n",
    "# or you need to rename the new columns:\n",
    "Ever_Married = pd.get_dummies(df['Ever_Married'], dtype=int)\n",
    "Ever_Married.rename(columns={'Yes':\"Married\", \"No\":'Not_Married'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把get dummies 的栏与原df合并，然后drop掉原栏\n",
    "df = pd.concat([df,sex_dummies,embarked_dummies],axis=1)\n",
    "df.drop(['sex','embarked'],axis=1, inplace=True)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define new metrics (e.g., multiply columns together or create custom categories based on multiple variables)\n",
    "mapping = {0:0, 1:1, 2:1, 3:1, 4:1}\n",
    "df['hd_cons'] = df['hd'].map(mapping)\n",
    "df.groupby('hd_cons').count()\n",
    "\n",
    "season_mapping = {1:'winter', 2:'spring', 3:'summer', 4:'fall'}\n",
    "df['season'] = df['season'].map(season_mapping)\n",
    "\n",
    "# apply function\n",
    "def good_bad(temp,hum):\n",
    "    if temp > 25 and hum > 70:\n",
    "        return 'too hot'\n",
    "    elif temp <=25 and hum >= 50 and hum <= 70:\n",
    "        return 'so so day'\n",
    "    else:\n",
    "        return 'good day'\n",
    "    \n",
    "df['day_type'] = df.apply(lambda x: good_bad(x['temp'], x['humidity']), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.data model\n",
    "# after you choose the variables, you can build the baseline of the models:\n",
    "x = df[['age', 'anaemia','ejection_fraction', 'high_blood_pressure',\n",
    "       'serum_creatinine', 'serum_sodium']]# the variable columns\n",
    "y = df['DEATH_EVENT'] # the target value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the StandardScalar to numerical column\n",
    "# Create a ColumnTransformer: apply StandardScaler on numerical columns and let other columns pass through\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), num)\n",
    "    ],\n",
    "    remainder='passthrough')\n",
    "\n",
    "# Fit the transformer using the training data\n",
    "X_train_transformed = preprocessor.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "log = LogisticRegression()\n",
    "nb = GaussianNB()\n",
    "svc = SVC()\n",
    "dtc= DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(x_train, y_train)\n",
    "log.fit(x_train, y_train)\n",
    "nb.fit(x_train, y_train)\n",
    "svc.fit(x_train, y_train)\n",
    "dtc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_knn = knn.predict(x_test)\n",
    "pred_log = log.predict(x_test)\n",
    "pred_nb = nb.predict(x_test)\n",
    "pred_sv = svc.predict(x_test)\n",
    "pred_dtc=dtc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f1_score(y_test,pred_knn))\n",
    "print(f1_score(y_test,pred_log))\n",
    "print(f1_score(y_test,pred_nb))\n",
    "print(f1_score(y_test,pred_sv))\n",
    "print(f1_score(y_test,pred_dtc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the coross-valuadation，if the 10 numbers have more than 10% difference will no be good.\n",
    "cv_scores_knn = cross_val_score(knn, x_train, y_train, cv=10, scoring='f1')\n",
    "cv_scores_nb = cross_val_score(nb, x_train, y_train, cv=10, scoring='f1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning\n",
    "# select parameters\n",
    "params_nb = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "params_knn = {'n_neighbors': list(range(1,200)), 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']}\n",
    "\n",
    "# 可以把range里的数调小一点，这里有200*2*2=400组\n",
    "\n",
    "# Define the models\n",
    "nb = GaussianNB()\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Define GridSearchCV---要根据题目决定选择recall 还是precision\n",
    "gridsearch_knn = GridSearchCV(knn, params_knn, cv=10, scoring='recall')\n",
    "    #nb, params_nb, cv=5)\n",
    "randomsearch_knn = RandomizedSearchCV(knn, params_knn, cv=10, n_iter = 50, scoring='recall')\n",
    "\n",
    "# Fit models\n",
    "gridsearch_knn.fit(x_train, y_train)\n",
    "randomsearch_knn.fit(x_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "print(\"Best parameters for KNN - gridsearch: \", gridsearch_knn.best_params_)\n",
    "print(\"Best parameters for KNN - randomsearch: \", randomsearch_knn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the best parameters\n",
    "nb_best = GaussianNB(**gridsearch_nb.best_params_)\n",
    "knn_best = KNeighborsClassifier(**gridsearch_knn.best_params_)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores_nb = cross_val_score(nb_best, x_train, y_train, cv=5, scoring='roc_auc')\n",
    "cv_scores_knn = cross_val_score(knn_best, x_train, y_train, cv=10, scoring='precision')\n",
    "\n",
    "#print(\"Cross-validation scores for Naive Bayes: \", cv_scores_nb)\n",
    "print(\"Cross-validation scores for KNN: \", cv_scores_knn)\n",
    "\n",
    "# Fit the models with the best parameters\n",
    "nb_best.fit(x_train, y_train)\n",
    "knn_best.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_nb = nb_best.predict(x_train)\n",
    "y_pred_knn = knn_best.predict(x_train)\n",
    "\n",
    "#print(\"Test accuracy for Naive Bayes: \", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Test accuracy for KNN: \", accuracy_score(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics\n",
    "print(\"Naive Bayes Metrics: \")\n",
    "print(\"Confusion Matrix: \", confusion_matrix(y_test, y_pred_nb))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred_nb))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_nb))\n",
    "print(\"F1 Score: \", f1_score(y_test, y_pred_nb))\n",
    "\n",
    "print(\"\\nK-Nearest Neighbors Metrics: \")\n",
    "print(\"Confusion Matrix: \", confusion_matrix(y_test, y_pred_knn))\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred_knn))\n",
    "print(\"Recall: \", recall_score(y_test, y_pred_knn))\n",
    "print(\"F1 Score: \", f1_score(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Predicted Probabilities\n",
    "knn_best_pred_prob = knn_best.predict_proba(X_test_transformed)\n",
    "knn_best_fpr, knn_best_tpr, knn_thresholds = roc_curve(y_test, knn_best_pred_prob[:, 1])\n",
    "\n",
    "# Logistic Regression Predicted Probabilities\n",
    "log_pred_prob = log.predict_proba(X_test_transformed)\n",
    "log_fpr, log_tpr, log_thresholds = roc_curve(y_test, log_pred_prob[:, 1])\n",
    "\n",
    "# Decision Tree Predicted Probabilities\n",
    "dtc_pred_prob = dtc.predict_proba(X_test_transformed)\n",
    "dtc_fpr, dtc_tpr, dtc_thresholds = roc_curve(y_test, dtc_pred_prob[:, 1])\n",
    "\n",
    "# Naive Bayes Predicted Probabilities\n",
    "nb_pred_prob = nb.predict_proba(X_test_transformed)\n",
    "nb_fpr, nb_tpr, nb_thresholds = roc_curve(y_test, dtc_pred_prob[:, 1])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "# Plot ROC for each model\n",
    "plt.plot(knn_best_fpr, knn_best_tpr, label='KNN_best')\n",
    "plt.plot(log_fpr, log_tpr, label='Logistic Regression')\n",
    "plt.plot(dtc_fpr, dtc_tpr, label='Decision Tree')\n",
    "plt.plot(nb_fpr, nb_tpr, label='Naive Bayes')\n",
    "# [Add plots for other models here]\n",
    "\n",
    "# Plot line for random classifier\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Multiple Models')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the pipeline:\n",
    "cat_columns = ['Pclass','Sex','Embarked']\n",
    "num_columns = ['Age','SibSp','Parch','Fare']\n",
    "target = 'Survived'\n",
    "\n",
    "cat_transformer = Pipeline(steps=[('passthrough', 'passthrough')])#if you dont need to transform the cat columns\n",
    "num_transformer = Pipeline(steps = [('scaler', StandardScaler())])#if you dont need to scarlar the numeric columns\n",
    "\n",
    "cat_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "num_transformer = StandardScaler()\n",
    "preprocessor = ColumnTransformer(transformers = [('cat',cat_transformer, cat_columns),\n",
    "                                                 ('num', num_transformer, num_columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[cat_columns + num_columns], df[target], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_transformed = preprocessor.fit_transform(X_train)\n",
    "x_test_transformed = preprocessor.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_columns = list(preprocessor.named_transformers_['cat'].get_feature_names_out(cat_columns))\n",
    "all_feat = num_columns + encoded_columns\n",
    "\n",
    "X_train_transformed = pd.DataFrame(x_train_transformed, columns=all_feat)\n",
    "X_test_transformed = pd.DataFrame(x_test_transformed, columns=all_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 40)\n",
    "knn.fit(X_train_transformed, y_train)\n",
    "y_pred = knn.predict(X_test_transformed)\n",
    "print(f1_score(y_pred, y_test))\n",
    "print(accuracy_score(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
