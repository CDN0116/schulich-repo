{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mp\n",
    "import statsmodels.api as sm\n",
    "from sklearn import linear_model as lm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.tsa.stattools import acf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('/Users/dylanbai/Desktop/Predictive Modeling/dataset_lm.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependent Var</th>\n",
       "      <th>Explanatory Var #1</th>\n",
       "      <th>Explanatory Var #2</th>\n",
       "      <th>Explanatory Var #3</th>\n",
       "      <th>Explanatory Var #4</th>\n",
       "      <th>Explanatory Var #5</th>\n",
       "      <th>Explanatory Var #6</th>\n",
       "      <th>Explanatory Var #7</th>\n",
       "      <th>Explanatory Var #8</th>\n",
       "      <th>Explanatory Var #9</th>\n",
       "      <th>Explanatory Var #10</th>\n",
       "      <th>Explanatory Var #11</th>\n",
       "      <th>Explanatory Var #12</th>\n",
       "      <th>Explanatory Var #13</th>\n",
       "      <th>Explanatory Var #14</th>\n",
       "      <th>Explanatory Var #15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.293458</td>\n",
       "      <td>13.698667</td>\n",
       "      <td>50.639873</td>\n",
       "      <td>0</td>\n",
       "      <td>-18.568035</td>\n",
       "      <td>45.121911</td>\n",
       "      <td>11.412501</td>\n",
       "      <td>56.410757</td>\n",
       "      <td>2</td>\n",
       "      <td>-12.281132</td>\n",
       "      <td>38.996909</td>\n",
       "      <td>-3.010548</td>\n",
       "      <td>49.195073</td>\n",
       "      <td>0</td>\n",
       "      <td>-21.153143</td>\n",
       "      <td>46.919314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>58.473431</td>\n",
       "      <td>2.714725</td>\n",
       "      <td>65.845845</td>\n",
       "      <td>1</td>\n",
       "      <td>-25.105932</td>\n",
       "      <td>47.190213</td>\n",
       "      <td>10.080280</td>\n",
       "      <td>65.383107</td>\n",
       "      <td>3</td>\n",
       "      <td>-36.763585</td>\n",
       "      <td>51.654939</td>\n",
       "      <td>4.991111</td>\n",
       "      <td>45.591729</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.474403</td>\n",
       "      <td>53.383508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94.195330</td>\n",
       "      <td>11.618072</td>\n",
       "      <td>65.072497</td>\n",
       "      <td>0</td>\n",
       "      <td>-7.897464</td>\n",
       "      <td>52.163036</td>\n",
       "      <td>11.057301</td>\n",
       "      <td>82.812717</td>\n",
       "      <td>0</td>\n",
       "      <td>-15.733547</td>\n",
       "      <td>48.913837</td>\n",
       "      <td>-2.457696</td>\n",
       "      <td>56.608806</td>\n",
       "      <td>0</td>\n",
       "      <td>-27.903299</td>\n",
       "      <td>48.515026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.074583</td>\n",
       "      <td>0.818623</td>\n",
       "      <td>45.408996</td>\n",
       "      <td>1</td>\n",
       "      <td>-18.316132</td>\n",
       "      <td>54.356714</td>\n",
       "      <td>5.029029</td>\n",
       "      <td>48.812471</td>\n",
       "      <td>1</td>\n",
       "      <td>-12.825591</td>\n",
       "      <td>45.851732</td>\n",
       "      <td>14.974177</td>\n",
       "      <td>47.362594</td>\n",
       "      <td>1</td>\n",
       "      <td>-10.064411</td>\n",
       "      <td>55.266254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>86.035569</td>\n",
       "      <td>9.077544</td>\n",
       "      <td>73.548021</td>\n",
       "      <td>0</td>\n",
       "      <td>-19.204165</td>\n",
       "      <td>47.186807</td>\n",
       "      <td>12.128134</td>\n",
       "      <td>62.520911</td>\n",
       "      <td>2</td>\n",
       "      <td>-13.804860</td>\n",
       "      <td>47.765904</td>\n",
       "      <td>9.593982</td>\n",
       "      <td>53.700562</td>\n",
       "      <td>0</td>\n",
       "      <td>-17.546302</td>\n",
       "      <td>48.150543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dependent Var  Explanatory Var #1  Explanatory Var #2  Explanatory Var #3   \n",
       "0      56.293458           13.698667           50.639873                   0  \\\n",
       "1      58.473431            2.714725           65.845845                   1   \n",
       "2      94.195330           11.618072           65.072497                   0   \n",
       "3      29.074583            0.818623           45.408996                   1   \n",
       "4      86.035569            9.077544           73.548021                   0   \n",
       "\n",
       "   Explanatory Var #4  Explanatory Var #5  Explanatory Var #6   \n",
       "0          -18.568035           45.121911           11.412501  \\\n",
       "1          -25.105932           47.190213           10.080280   \n",
       "2           -7.897464           52.163036           11.057301   \n",
       "3          -18.316132           54.356714            5.029029   \n",
       "4          -19.204165           47.186807           12.128134   \n",
       "\n",
       "   Explanatory Var #7  Explanatory Var #8  Explanatory Var #9   \n",
       "0           56.410757                   2          -12.281132  \\\n",
       "1           65.383107                   3          -36.763585   \n",
       "2           82.812717                   0          -15.733547   \n",
       "3           48.812471                   1          -12.825591   \n",
       "4           62.520911                   2          -13.804860   \n",
       "\n",
       "   Explanatory Var #10  Explanatory Var #11  Explanatory Var #12   \n",
       "0            38.996909            -3.010548            49.195073  \\\n",
       "1            51.654939             4.991111            45.591729   \n",
       "2            48.913837            -2.457696            56.608806   \n",
       "3            45.851732            14.974177            47.362594   \n",
       "4            47.765904             9.593982            53.700562   \n",
       "\n",
       "   Explanatory Var #13  Explanatory Var #14  Explanatory Var #15  \n",
       "0                    0           -21.153143            46.919314  \n",
       "1                    0            -6.474403            53.383508  \n",
       "2                    0           -27.903299            48.515026  \n",
       "3                    1           -10.064411            55.266254  \n",
       "4                    0           -17.546302            48.150543  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 422 entries, 0 to 421\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Dependent Var        422 non-null    float64\n",
      " 1   Explanatory Var #1   422 non-null    float64\n",
      " 2   Explanatory Var #2   422 non-null    float64\n",
      " 3   Explanatory Var #3   422 non-null    int64  \n",
      " 4   Explanatory Var #4   422 non-null    float64\n",
      " 5   Explanatory Var #5   422 non-null    float64\n",
      " 6   Explanatory Var #6   422 non-null    float64\n",
      " 7   Explanatory Var #7   422 non-null    float64\n",
      " 8   Explanatory Var #8   422 non-null    int64  \n",
      " 9   Explanatory Var #9   422 non-null    float64\n",
      " 10  Explanatory Var #10  422 non-null    float64\n",
      " 11  Explanatory Var #11  422 non-null    float64\n",
      " 12  Explanatory Var #12  422 non-null    float64\n",
      " 13  Explanatory Var #13  422 non-null    int64  \n",
      " 14  Explanatory Var #14  422 non-null    float64\n",
      " 15  Explanatory Var #15  422 non-null    float64\n",
      "dtypes: float64(13), int64(3)\n",
      "memory usage: 52.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          Dependent Var   R-squared:                       1.000\n",
      "Model:                            OLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 7.593e+30\n",
      "Date:                Wed, 25 Oct 2023   Prob (F-statistic):               0.00\n",
      "Time:                        10:59:51   Log-Likelihood:                 12339.\n",
      "No. Observations:                 422   AIC:                        -2.465e+04\n",
      "Df Residuals:                     406   BIC:                        -2.458e+04\n",
      "Df Model:                          15                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  32.0000   4.32e-14    7.4e+14      0.000      32.000      32.000\n",
      "Explanatory Var #1      1.3000   3.49e-16   3.72e+15      0.000       1.300       1.300\n",
      "Explanatory Var #2      1.7000   2.54e-16    6.7e+15      0.000       1.700       1.700\n",
      "Explanatory Var #3      6.2000   4.87e-15   1.27e+15      0.000       6.200       6.200\n",
      "Explanatory Var #4      2.1000      3e-16      7e+15      0.000       2.100       2.100\n",
      "Explanatory Var #5     -0.9000   3.51e-16  -2.56e+15      0.000      -0.900      -0.900\n",
      "Explanatory Var #6  -3.842e-16   2.12e-16     -1.812      0.071   -8.01e-16    3.27e-17\n",
      "Explanatory Var #7  -9.626e-16   1.64e-16     -5.876      0.000   -1.28e-15   -6.41e-16\n",
      "Explanatory Var #8  -2.789e-15   2.23e-15     -1.253      0.211   -7.17e-15    1.59e-15\n",
      "Explanatory Var #9   7.033e-16   2.85e-16      2.471      0.014    1.44e-16    1.26e-15\n",
      "Explanatory Var #10 -5.371e-16   3.55e-16     -1.514      0.131   -1.23e-15     1.6e-16\n",
      "Explanatory Var #11 -1.433e-15   3.43e-16     -4.178      0.000   -2.11e-15   -7.59e-16\n",
      "Explanatory Var #12  1.064e-15   2.57e-16      4.146      0.000     5.6e-16    1.57e-15\n",
      "Explanatory Var #13 -1.977e-14   4.92e-15     -4.020      0.000   -2.94e-14   -1.01e-14\n",
      "Explanatory Var #14 -5.991e-16   3.02e-16     -1.985      0.048   -1.19e-15   -5.64e-18\n",
      "Explanatory Var #15 -3.694e-15    3.6e-16    -10.274      0.000    -4.4e-15   -2.99e-15\n",
      "==============================================================================\n",
      "Omnibus:                        1.606   Durbin-Watson:                   1.878\n",
      "Prob(Omnibus):                  0.448   Jarque-Bera (JB):                1.555\n",
      "Skew:                           0.149   Prob(JB):                        0.460\n",
      "Kurtosis:                       2.990   Cond. No.                     2.55e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.55e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "y = df.iloc[:,0]# target value\n",
    "x = sm.add_constant(df.iloc[:,1:])# predictive values\n",
    "\n",
    "\n",
    "# Create and fit the OLS model\n",
    "model_reg = sm.OLS(y, x).fit()\n",
    "\n",
    "# Print the summary\n",
    "print(model_reg.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard Deviation of Residuals: 4.8420848299516345e-14\n",
      "Autocorrelation 3Lags: [ 1.          0.05825183  0.08620278 -0.01215877]\n"
     ]
    }
   ],
   "source": [
    "# Get the residuals (errors) from the OLS model\n",
    "residuals = model_reg.resid\n",
    "\n",
    "# Calculate the standard deviation of the residuals\n",
    "residuals_std_dev = np.std(residuals)\n",
    "\n",
    "# Calculate autocorrelation values for the first three lags\n",
    "lags = 3\n",
    "autocorr_values = acf(residuals, nlags=lags)\n",
    "\n",
    "\n",
    "# Print the results\n",
    "print(\"Standard Deviation of Residuals:\", residuals_std_dev)\n",
    "print(\"Autocorrelation 3Lags:\", autocorr_values)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            GLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          Dependent Var   R-squared:                       1.000\n",
      "Model:                            GLS   Adj. R-squared:                  1.000\n",
      "Method:                 Least Squares   F-statistic:                 1.790e+30\n",
      "Date:                Wed, 25 Oct 2023   Prob (F-statistic):               0.00\n",
      "Time:                        11:17:32   Log-Likelihood:                 12034.\n",
      "No. Observations:                 422   AIC:                        -2.404e+04\n",
      "Df Residuals:                     406   BIC:                        -2.397e+04\n",
      "Df Model:                          15                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "const                  32.0000   8.91e-14   3.59e+14      0.000      32.000      32.000\n",
      "Explanatory Var #1      1.3000   7.19e-16   1.81e+15      0.000       1.300       1.300\n",
      "Explanatory Var #2      1.7000   5.22e-16   3.25e+15      0.000       1.700       1.700\n",
      "Explanatory Var #3      6.2000      1e-14   6.18e+14      0.000       6.200       6.200\n",
      "Explanatory Var #4      2.1000   6.18e-16    3.4e+15      0.000       2.100       2.100\n",
      "Explanatory Var #5     -0.9000   7.24e-16  -1.24e+15      0.000      -0.900      -0.900\n",
      "Explanatory Var #6  -2.906e-16   4.37e-16     -0.665      0.506   -1.15e-15    5.68e-16\n",
      "Explanatory Var #7  -1.918e-15   3.37e-16     -5.685      0.000   -2.58e-15   -1.25e-15\n",
      "Explanatory Var #8  -2.473e-15   4.59e-15     -0.539      0.590   -1.15e-14    6.54e-15\n",
      "Explanatory Var #9   1.498e-15   5.86e-16      2.555      0.011    3.45e-16    2.65e-15\n",
      "Explanatory Var #10 -9.035e-16   7.31e-16     -1.236      0.217   -2.34e-15    5.33e-16\n",
      "Explanatory Var #11  -1.87e-15   7.07e-16     -2.646      0.008   -3.26e-15   -4.81e-16\n",
      "Explanatory Var #12 -1.626e-15   5.29e-16     -3.075      0.002   -2.66e-15   -5.86e-16\n",
      "Explanatory Var #13 -2.676e-14   1.01e-14     -2.642      0.009   -4.67e-14   -6.85e-15\n",
      "Explanatory Var #14  3.116e-15   6.22e-16      5.011      0.000    1.89e-15    4.34e-15\n",
      "Explanatory Var #15  8.672e-17    7.4e-16      0.117      0.907   -1.37e-15    1.54e-15\n",
      "==============================================================================\n",
      "Omnibus:                        2.686   Durbin-Watson:                   0.628\n",
      "Prob(Omnibus):                  0.261   Jarque-Bera (JB):                2.227\n",
      "Skew:                           0.053   Prob(JB):                        0.328\n",
      "Kurtosis:                       2.660   Cond. No.                     2.55e+03\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.55e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dylanbai/Library/Python/3.9/lib/python/site-packages/statsmodels/base/model.py:130: ValueWarning: unknown kwargs ['rho']\n",
      "  warnings.warn(msg, ValueWarning)\n"
     ]
    }
   ],
   "source": [
    "gls_model = sm.GLS(y, x, sigma=residuals_std_dev, rho=autocorr_values)\n",
    "\n",
    "# Fit the GLS model\n",
    "gls_results = gls_model.fit()\n",
    "\n",
    "# Print GLS model summary\n",
    "print(gls_results.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model as lm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.28627322,  1.69892027,  2.13101131,  2.09333311, -0.91133961,\n",
       "       -0.        ,  0.00312807, -0.        , -0.        ,  0.        ,\n",
       "        0.0079738 ,  0.        , -0.        ,  0.        , -0.        ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_ext = x.drop(columns=['const'])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_ext,y, test_size=0.5, random_state=1234)\n",
    "model_lasso = lm.Lasso(alpha=1).fit(x_train,y_train)\n",
    "model_lasso.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error (MAPE) - Lasso (alpha = 1): 3.9683173200473947%\n",
      "Mean Absolute Percentage Error (alpha=0.001): 3.979710792045792e-05\n",
      "Mean Absolute Percentage Error (alpha=0.01): 0.0003969254557591966\n",
      "Mean Absolute Percentage Error (alpha=0.1): 0.003968773400703293\n",
      "Mean Absolute Percentage Error (alpha=1): 0.039683173200473945\n",
      "Mean Absolute Percentage Error (alpha=10): 0.0724188108097429\n",
      "Mean Absolute Percentage Error (alpha=100): 0.42398947658185043\n"
     ]
    }
   ],
   "source": [
    "#  Calculate mean absolute percentage error using the test set\n",
    "predictions = model_lasso.predict(x_test)\n",
    "mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "print(f\"Mean Absolute Percentage Error (MAPE) - Lasso (alpha = 1): {mape*100}%\")\n",
    "\n",
    "# Find an approximate value for alpha that minimizes the MAPE\n",
    "best_alpha = None\n",
    "best_mape = float('inf')\n",
    "\n",
    "# Test different alpha values in a loop\n",
    "alpha_values = [0.001, 0.01, 0.1, 1, 10, 100]  # You can adjust this list based on your problem\n",
    "for alpha in alpha_values:\n",
    "    lasso_model = lm.Lasso(alpha=alpha)\n",
    "    lasso_model.fit(x_train, y_train)\n",
    "    predictions = lasso_model.predict(x_test)\n",
    "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "    \n",
    "    print(f\"Mean Absolute Percentage Error (alpha={alpha}): {mape}\")\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe using the data provided\n",
    "demand = pd.DataFrame()\n",
    "\n",
    "actual = [100, 112, 107, 103, 91,\n",
    "            85, 84, 85, 79, 81,\n",
    "            134, 86, 99, 89, 111,\n",
    "            114, 118, 163, 193, 143,\n",
    "            144, 202, 158, 160, 144]\n",
    "\n",
    "advance = [71, 30, 75, 64, 41,\n",
    "            51, 42, 51, 57, 49,\n",
    "            134, 52, 99, 56, 81,\n",
    "            79, 73, 163, 193, 99,\n",
    "            91, 202, 105, 101, 96]\n",
    "\n",
    "demand['month'] = np.arange(1,26)\n",
    "demand['act_demand'] = actual\n",
    "demand['adv_demand'] = advance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = demand[['month', 'adv_demand']]\n",
    "y = demand['act_demand']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 13.682095805816964\n",
      "Coefficients: [1.19848313 0.5571767 ]\n",
      "Intercept: 56.226108746626366\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Elastic Net model\n",
    "alpha = 0.1  # Regularization strength (you can adjust this)\n",
    "l1_ratio = 0.5  # Mix ratio between L1 and L2 regularization (you can adjust this)\n",
    "elastic_net_model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio)\n",
    "elastic_net_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "predictions = elastic_net_model.predict(X_test)\n",
    "\n",
    "# Calculate RMSE (Root Mean Squared Error) to evaluate the model\n",
    "rmse = sqrt(mean_squared_error(y_test, predictions))\n",
    "print(f'Root Mean Squared Error: {rmse}')\n",
    "\n",
    "# You can also interpret the coefficients of the model to understand feature importance\n",
    "coefficients = elastic_net_model.coef_\n",
    "intercept = elastic_net_model.intercept_\n",
    "\n",
    "print(f'Coefficients: {coefficients}')\n",
    "print(f'Intercept: {intercept}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
